{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 647 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 140s 20ms/step - loss: 4.8559 - acc: 0.0066 - val_loss: 4.8521 - val_acc: 0.0077\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 139s 20ms/step - loss: 4.8529 - acc: 0.0057 - val_loss: 4.8521 - val_acc: 0.0077\n",
      "Epoch 3/10\n",
      "3968/7000 [================>.............] - ETA: 1:01 - loss: 4.8523 - acc: 0.0033"
     ]
    }
   ],
   "source": [
    "# Python 3.7.4\n",
    "# Handwritten Chinese Character Classification\n",
    "\n",
    "from gnt import GNT\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import scipy.misc\n",
    "\n",
    "# step = 1246991  # 全局变量，每次处理step个图片，防止占用太多内存，可以根据实际情况更改\n",
    "step_train = 7000  # 全局变量，每次处理step个图片，防止占用太多内存，可以根据实际情况更改\n",
    "step_test = 647\n",
    "threshold = 220  # 二值图阈值\n",
    "TargetSize = 64  # 目标图片的边长\n",
    "train_times = 10  # 迭代次数\n",
    "\n",
    "# 从数据集中提取部分样本\n",
    "def GetPictures(gnt, imgs, labels):\n",
    "    for img, label in gnt:\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "# 将灰度图转为二值图    \n",
    "def Gray2binary(table, img):\n",
    "    img = img.convert('P')\n",
    "    img = img.point(table, '1')\n",
    "    return img\n",
    "\n",
    "# 处理中文标签\n",
    "def StrL2IntL(labels, labels_str):\n",
    "    if labels[i] in labels_str:\n",
    "        labels[i] = labels_str.index(labels[i])\n",
    "    else:\n",
    "        labels_str.append(labels[i])\n",
    "        labels[i] = len(labels_str) - 1\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "# path为数据集目录\n",
    "# root = 'D:\\data\\课程\\人工智能\\手写文本数据库'\n",
    "# file为文件名\n",
    "# file = 'competition-gnt.zip'\n",
    "\n",
    "Z = zipfile.ZipFile('../data/competition-gnt.zip')  # 数据集为压缩包形式\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "labels_str = []\n",
    "\n",
    "for i in range (0, 60):\n",
    "    set_name = Z.namelist()[i]  # 取压缩包中的第i个数据集\n",
    "    gnt = GNT(Z, set_name)  # gnt即包含了目标数据集中的所有数据，形式为：(img, label)\n",
    "    GetPictures(gnt, imgs, labels)  # 获取数据集中的step个训练数据\n",
    "\n",
    "sub_labels = labels[0:128]\n",
    "sub_imgs = imgs[0:128]\n",
    "img = 128\n",
    "for i in labels[128:-1]:\n",
    "    if i in sub_labels:\n",
    "        sub_labels.append(i)\n",
    "        sub_imgs.append(imgs[img])\n",
    "    img = img + 1\n",
    "\n",
    "imgs_train = sub_imgs[0: step_train]\n",
    "labels_train = sub_labels[0: step_train]\n",
    "imgs_test = sub_imgs[step_train: step_train + step_test]\n",
    "labels_test = sub_labels[step_train: step_train + step_test]\n",
    "\n",
    "table = []\n",
    "for i in range(256):\n",
    "    if i < threshold:\n",
    "        table.append(0)\n",
    "    else:\n",
    "        table.append(1)\n",
    "\n",
    "# 训练数据集\n",
    "for i in range(0, step_train):  # 统一图片大小\n",
    "    imgs_train[i] = Image.fromarray(imgs_train[i])\n",
    "    # imgs[i] = Gray2binary(table, imgs[i])  # 将灰度图转为二值图\n",
    "    imgs_train[i] = imgs_train[i].resize((TargetSize, TargetSize))\n",
    "    imgs_train[i] = np.array(imgs_train[i])\n",
    "    StrL2IntL(labels_train, labels_str)  # 处理中文标签\n",
    "\n",
    "# 测试数据集\n",
    "for i in range(0, step_test):  # 统一图片大小\n",
    "    imgs_test[i] = Image.fromarray(imgs_test[i])\n",
    "    # imgs_test[i] = Gray2binary(table, imgs_test[i])  # 将灰度图转为二值图\n",
    "    imgs_test[i] = imgs_test[i].resize((TargetSize, TargetSize))\n",
    "    imgs_test[i] = np.array(imgs_test[i])\n",
    "    StrL2IntL(labels_test, labels_str)  # 处理中文标签\n",
    "    \n",
    "# 改变张量形状\n",
    "imgs_train = np.array(imgs_train)\n",
    "'''\n",
    "imgs = imgs.reshape((step, TargetSize * TargetSize))\n",
    "'''\n",
    "imgs_train = imgs_train.reshape((step_train, TargetSize, TargetSize, 1))\n",
    "imgs_train = imgs_train.astype(\"float\") / 255\n",
    "imgs_test = np.array(imgs_test)\n",
    "'''\n",
    "imgs_test = imgs_test.reshape((step_test, TargetSize * TargetSize))\n",
    "'''\n",
    "imgs_test = imgs_test.reshape((step_test, TargetSize, TargetSize, 1))\n",
    "imgs_test = imgs_test.astype(\"float\") / 255\n",
    "\n",
    "# 构建网络\n",
    "network = models.Sequential()\n",
    "network.add(layers.Conv2D(256, (3, 3), activation='relu', input_shape=(TargetSize, TargetSize, 1)))\n",
    "network.add(layers.MaxPooling2D((2, 2)))\n",
    "network.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "network.add(layers.MaxPooling2D((2, 2)))\n",
    "network.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "network.add(layers.MaxPooling2D((2, 2)))\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(len(labels_str), activation='softmax'))\n",
    "\n",
    "# 编译\n",
    "network.compile(optimizer = 'adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# 训练\n",
    "labels_train = np.array(labels_train)\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_test = np.array(labels_test)\n",
    "labels_test = to_categorical(labels_test)\n",
    "history = network.fit(imgs_train, labels_train, epochs=train_times, batch_size=128, validation_data=(imgs_test, labels_test))\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label = 'Loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label = 'val_loss')\n",
    "plt.title('Loss of train and val')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 测试\n",
    "test_loss, test_acc = network.evaluate(imgs_test, labels_test)\n",
    "network.save('HCCC_subset.h5')\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
