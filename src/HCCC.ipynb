{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 62, 62, 512)       5120      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 31, 31, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 29, 29, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               37749248  \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3740)              1918620   \n",
      "=================================================================\n",
      "Total params: 44,392,604\n",
      "Trainable params: 44,392,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# Python 3.7.4\n",
    "# Handwritten Chinese Character Classification\n",
    "\n",
    "from gnt import GNT\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# step = 1246991  # 全局变量，每次处理step个图片，防止占用太多内存，可以根据实际情况更改\n",
    "step = 10000  # 全局变量，每次处理step个图片，防止占用太多内存，可以根据实际情况更改\n",
    "step_test = 3000\n",
    "threshold = 220  # 二值图阈值\n",
    "TargetSize = 64  # 目标图片的边长\n",
    "train_times = 100  # 迭代次数\n",
    "\n",
    "# 从数据集中提取部分样本\n",
    "def GetPictures(gnt, imgs, labels, imgs_test, labels_test):\n",
    "    i = 0\n",
    "    step2 = step + step_test\n",
    "    for img, label in gnt:\n",
    "        if i < step:\n",
    "            imgs[i] = img\n",
    "            labels[i] = label\n",
    "        elif i < step2:\n",
    "            imgs_test[i - step] = img\n",
    "            labels_test[i - step] = label\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "# 将灰度图转为二值图    \n",
    "def Gray2binary(table, img):\n",
    "    img = img.convert('P')\n",
    "    img = img.point(table, '1')\n",
    "    return img\n",
    "\n",
    "# 处理中文标签\n",
    "def StrL2IntL(labels, labels_str):\n",
    "    if labels[i] in labels_str:\n",
    "        labels[i] = labels_str.index(labels[i])\n",
    "    else:\n",
    "        labels_str.append(labels[i])\n",
    "        labels[i] = len(labels_str) - 1\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "# path为数据集目录\n",
    "root = 'D:\\data\\课程\\人工智能\\手写文本数据库'\n",
    "# file为文件名\n",
    "file = 'HWDB1.0trn_gnt.zip'\n",
    "\n",
    "Z = zipfile.ZipFile(f'{root}\\{file}')  # 数据集为压缩包形式\n",
    "set_name = Z.namelist()[0]  # 取压缩包中的第一个数据集\n",
    "gnt = GNT(Z, set_name)  # gnt即包含了目标数据集中的所有数据，形式为：(img, label)\n",
    "\n",
    "imgs = [0 for x in range(0, step)]\n",
    "labels = [0 for x in range(0, step)]\n",
    "labels_str = []\n",
    "imgs_test = [0 for x in range(0, step_test)]\n",
    "labels_test = [0 for x in range(0, step_test)]\n",
    "GetPictures(gnt, imgs, labels, imgs_test, labels_test)  # 获取数据集中的step个训练数据\n",
    "table = []\n",
    "for i in range(256):\n",
    "    if i < threshold:\n",
    "        table.append(0)\n",
    "    else:\n",
    "        table.append(1)\n",
    "\n",
    "# 训练数据集\n",
    "for i in range(0, step):  # 统一图片大小\n",
    "    imgs[i] = Image.fromarray(imgs[i])\n",
    "    # imgs[i] = Gray2binary(table, imgs[i])  # 将灰度图转为二值图\n",
    "    imgs[i] = imgs[i].resize((TargetSize, TargetSize))\n",
    "    imgs[i] = np.array(imgs[i])\n",
    "    StrL2IntL(labels, labels_str)  # 处理中文标签\n",
    "\n",
    "# 测试数据集\n",
    "for i in range(0, step_test):  # 统一图片大小\n",
    "    imgs_test[i] = Image.fromarray(imgs_test[i])\n",
    "    # imgs_test[i] = Gray2binary(table, imgs_test[i])  # 将灰度图转为二值图\n",
    "    imgs_test[i] = imgs_test[i].resize((TargetSize, TargetSize))\n",
    "    imgs_test[i] = np.array(imgs_test[i])\n",
    "    StrL2IntL(labels_test, labels_str)  # 处理中文标签\n",
    "\n",
    "# 改变张量形状\n",
    "imgs = np.array(imgs)\n",
    "'''\n",
    "imgs = imgs.reshape((step, TargetSize * TargetSize))\n",
    "'''\n",
    "imgs = imgs.reshape((step, TargetSize, TargetSize, 1))\n",
    "imgs = imgs.astype(\"float\") / 255\n",
    "imgs_test = np.array(imgs_test)\n",
    "'''\n",
    "imgs_test = imgs_test.reshape((step_test, TargetSize * TargetSize))\n",
    "'''\n",
    "imgs_test = imgs_test.reshape((step_test, TargetSize, TargetSize, 1))\n",
    "imgs_test = imgs_test.astype(\"float\") / 255\n",
    "\n",
    "# 构建网络\n",
    "network = models.Sequential()\n",
    "'''\n",
    "network.add(layers.Dense(4096, activation = 'relu', input_shape = (TargetSize * TargetSize, )))\n",
    "network.add(layers.Dense(4096, activation = 'relu'))\n",
    "network.add(layers.Dense(4096, activation = 'relu'))\n",
    "network.add(layers.Dense(len(labels_str), activation='softmax'))\n",
    "'''\n",
    "network.add(layers.Conv2D(512, (3, 3), activation='relu', input_shape=(TargetSize, TargetSize, 1)))\n",
    "network.add(layers.MaxPooling2D((2, 2)))\n",
    "network.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "network.add(layers.MaxPooling2D((2, 2)))\n",
    "network.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(len(labels_str), activation='softmax'))\n",
    "print(network.summary())\n",
    "\n",
    "# 编译\n",
    "network.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# 训练\n",
    "labels = np.array(labels)\n",
    "labels = to_categorical(labels)\n",
    "network.fit(imgs, labels, epochs=train_times, batch_size=128)\n",
    "\n",
    "# 测试\n",
    "labels_test = np.array(labels_test)\n",
    "labels_test = to_categorical(labels_test)\n",
    "test_loss, test_acc = network.evaluate(imgs_test, labels_test)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
